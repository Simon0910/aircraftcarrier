package ${cfg.ImportCmdExe_p};

import cn.hutool.core.collection.CollUtil;
import cn.hutool.core.text.CharSequenceUtil;
import com.aircraftcarrier.framework.excel.util.BatchRowListener;
import com.aircraftcarrier.framework.excel.util.EasyExcelReadUtil;
import com.aircraftcarrier.framework.exception.SysException;
import com.aircraftcarrier.framework.model.BatchResult;
import com.aircraftcarrier.framework.model.response.SingleResponse;
import com.aircraftcarrier.framework.tookit.BeanUtil;
import com.aircraftcarrier.framework.tookit.MapUtil;
import com.aircraftcarrier.framework.tookit.StringPool;
import ${cfg.ImportCmd_f};
import ${cfg.Import_f};
import ${cfg.Repository_f};
import ${cfg.Do_f};
import com.alibaba.excel.context.AnalysisContext;
import lombok.extern.slf4j.Slf4j;
import org.springframework.stereotype.Component;
import org.springframework.web.multipart.MultipartFile;

import javax.annotation.Resource;
import java.io.IOException;
import java.io.InputStream;
import java.util.ArrayList;
import java.util.HashMap;
import java.util.List;
import java.util.Objects;
import java.util.concurrent.ConcurrentHashMap;
import java.util.stream.Collectors;


/**
 * 批量导入 执行类
 *
 * @author ${author}
 * @date ${date}
 * @since 1.0
 */
@Slf4j
@Component
public class ${cfg.ImportCmdExe_n} {
    /**
     * 全局初始化容器大小
     */
    private static final int GLOBAL_SIZE = 1000 << 1;
    /**
     * 初始化容器大小
     */
    private static final int SIZE = 1000;


    /**
     * ${cfg.Repository_n}
     */
    @Resource
    #set ($gatewayI = ${cfg.Repository_n_i})
    private ${cfg.Repository_n} ${gatewayI};

    /**
     * execute
     *
     * @param importCmd importCmd
     * @return SingleResponse<BatchResult>
     */
    public SingleResponse<BatchResult> execute(${cfg.ImportCmd_n} importCmd) {
        MultipartFile file = importCmd.getFile();
        InputStream inputStream;
        try {
            inputStream = file.getInputStream();
        } catch (IOException e) {
            e.printStackTrace();
            throw new SysException("file error");
        }

        ${cfg.Import_n}Upload upload = new ${cfg.Import_n}Upload();
        EasyExcelReadUtil.checkExcelFile(file);
        EasyExcelReadUtil.readBatchRow(inputStream, ${cfg.Import_n}.class, 0, 0, 1, upload);
        return SingleResponse.ok(upload.getBatchResult());
    }


    /**
     * 上传类
     */
    class ${cfg.Import_n}Upload implements BatchRowListener<${cfg.Import_n}> {
        // 全局数据和数据库保持一致
        HashMap<Integer, Integer> insertMap = MapUtil.newHashMap(GLOBAL_SIZE);
        // 所有批次的重复数据, 第一条数据
        ConcurrentHashMap<Integer, String> globalRepeatMap = MapUtil.newConcurrentHashMap(GLOBAL_SIZE);
        // 和Excel读取数据保持一致的数据(去除残缺的数据)
        HashMap<String, Integer> uniqueMap = MapUtil.newHashMap(GLOBAL_SIZE);
        // 上传结果
        BatchResult batchResult = new BatchResult();

        @Override
        public void batchInvoke(List<${cfg.Import_n}> rowList, AnalysisContext analysisContext) {
            // 临时容器
            List<ProductDetailsImport> tempResult = new ArrayList<>(SIZE);
            // 临时的重复数据, 第一条数据
            HashMap<Integer, String> tempRepeatMap = MapUtil.newHashMap(SIZE);
            // 遍历当前批次
            for (${cfg.Import_n} row : rowList) {
                boolean ok = checkNullField(row);
                if (!ok) {
                    continue;
                }
                ok = checkRepeatRow(row, tempRepeatMap);
                if (!ok) {
                    continue;
                }
                ok = checkByDb(row);
                if (!ok) {
                    continue;
                }
                tempResult.add(row);
            }

            if (!tempRepeatMap.isEmpty()) {
                // 过滤掉之前添加过的所有重复的数据
                logger.info("tempRepeatMap.size: {}", tempRepeatMap.size());
                tempResult = tempResult.stream().filter(e -> tempRepeatMap.get(e.getRowNo()) == null).collect(Collectors.toList());
            }
            // do insert
            doSaveBatch(tempResult);
            for (ProductDetailsImport productDetailsImport : tempResult) {
                insertMap.put(productDetailsImport.getRowNo(), productDetailsImport.getRowNo());
            }
            tempResult.clear();
            tempRepeatMap.clear(); // help gc
        }

        /**
         * 保存数据库
         *
         * @param imports imports
         */
        public void doSaveBatch(List<${cfg.Import_n}> imports) {
            log.info("imports.size: {}", imports.size());
            if (CollUtil.isEmpty(imports)) {
                return;
            }
            // do saveBatch ...
            List<${entity}> list = BeanUtil.convertList(imports, ${entity}.class);
            ${gatewayI}.saveBatch(list);
            batchResult.increaseSuccess(imports.size());
        }

        /**
         * 根据业务场景需要对别校验数据库
         *
         * @param row row
         * @return boolean
         */
        private boolean checkByDb(${cfg.Import_n} row) {
            // todo query DB...
            if (row.getRowNo() == null) {
                return false;
            }
            return true;
        }

        /**
         * 重复行校验
         * 重复数据需根据具体业务定义
         * oldRowNo: 第一次检测到全局重复数据的的行号
         * <p>
         * 注@1: 不能避免 单批次数据都正常（会保存到DB），读之后批次时又发现了和之前存在重复的数据
         * 1.要么不要分批读取，但失去了大批量分批读的意义。（要求严格数据要一次读全部,比如多颗数结构校验存在前后业务关联，又要和数据库对比，非常复杂）
         * 2.要么处理之后批时候，把之前批的那条记录查DB校验一下确实是本次上传保存的，执行删除，这样就比较复杂了.
         * 3.要么不处理，默认之前批的那条成功就成功了，本此上传的保存不会产生重复数据的保存
         *
         * @param row           row
         * @param tempRepeatMap 本批次保存需要过滤到数据
         * @return boolean
         */
        private boolean checkRepeatRow(${cfg.Import_n} row, HashMap<Integer, String> tempRepeatMap) {
            Integer oldRowNo = uniqueMap.putIfAbsent(row.genUniqueKey(), row.getRowNo());
            if (oldRowNo == null) {
                return true;
            }

            // 到这里说明之前读过了这样的数据 (是和之前批重复还是和本批次重复呢？此时不确定)
            String flag = globalRepeatMap.putIfAbsent(oldRowNo, StringPool.EMPTY);
            if (flag == null) {
                // 到这里说明 记录了第一条全局重复数据
                // 加到临时容器，作用是过滤保存到临时数据
                tempRepeatMap.put(oldRowNo, StringPool.EMPTY);
                if (insertMap.get(oldRowNo) == null) {
                    // @2没有保存到数据库, 此时说明是和本批次到重复（发现到这两条数据@2@3重复数据不保存）
                    batchResult.addErrorMsg(oldRowNo, "与第[" + row.getRowNo() + "]行数据重复");
                }
                // else 如果是之前保存过数据库, 说明是和之前批次重复了，除第一条保存了@1，之后的所有批次的所有重复行@3不保存
            }

            // @3当前数据 和 第一次检测到全局重复数据的的行号重复, return false 肯定不会加到临时容器
            batchResult.addErrorMsg(row.getRowNo(), "与第[" + oldRowNo + "]行数据重复");
            return false;
        }

        /**
         * checkNullField
         * 如果必要，可能要手写枚举校验
         *
         * @param row row
         * @return boolean
         */
        private boolean checkNullField(${cfg.Import_n} row) {
    #foreach($field in ${table.fields})
        #set ($sfN = ${field.propertyName.substring(0, 1).toUpperCase()} + ${field.propertyName.substring(1)})
        #if("$!field.propertyType" == "String")
            if (CharSequenceUtil.isBlank(row.get${sfN}())) {
                batchResult.addErrorMsg(row.getRowNo(), "${field.comment}为空");
                return false;
            }
        #else
            if (Objects.isNull(row.get${sfN}())) {
                batchResult.addErrorMsg(row.getRowNo(), "${field.comment}为null");
                return false;
            }
        #end
    #end
            return true;
        }

        /**
         * 获取最终上传结果
         *
         * @return BatchResult
         */
        public BatchResult getBatchResult() {
            return batchResult;
        }
    }

}
